---
title: "Econometrics 2B: Time Series Analysis - Homework"
author: "Tim Kühleis, Bartolomeo Perazzoli"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r setup_and_data, include=FALSE}

# Setting up the Homework

# Load necessary Packages 
if (!require("pacman")) install.packages("pacman")
pacman::p_load(tidyr, fredr, dplyr, ggplot2, patchwork, urca, tseries, zoo, vars, forecast, patchwork, Metrics, gridExtra, knitr, kableExtra, purrr, tibble, scales, xtable, lubridate)

# Retrieve the Data from FRED using their API ----
### (You need an API Key to retrieve the Data, feel free to use mine for this 

fredr_set_key("8af1b2f98eef41dfe4b5ff6ffce1bbb0")

# Define sample window
start_date <- as.Date("2000-01-01")
end_date   <- as.Date("2019-12-31")

# 1. Germany industrial activity index (monthly, Seasonally Adjusted)
industrial <- fredr(
  series_id         = "DEUPROINDMISMEI",
  observation_start = start_date,
  observation_end   = end_date,
  frequency         = "m"
)

# 2. Retrieve BAML High-Yield OAS (aggregated to monthly avg., no SA needed)
credit_spread <- fredr(
  series_id           = "BAMLHE00EHYIOAS",
  observation_start   = start_date,
  observation_end     = end_date,
  frequency            = "m",       # monthly frequency
  aggregation_method   = "avg"      # average of daily values
)

# 3. Germany CPI (monthly, Seasonally ajusted data)
## Originally in our Mail we used the non SA data but SA-adjusted was available too so we switched 
cpi <- fredr(
  series_id         = "DEUCPALTT01IXOBSAM",
  observation_start = start_date,
  observation_end   = end_date,
  frequency         = "m"
) 

# Inspecting data briefly
head(industrial)
head(cpi)
head(credit_spread)
```

# Exercise 1 - Univariate Analysis

## Exercise 1.1: Plot each time-series in levels before applying any transformations

```{r exercise_1/1_plots, include=FALSE}
# Combine data into long format
data_raw <- bind_rows(
  credit_spread %>% 
    dplyr::select(date, value) %>%  # Prev. Problems with select fixed, explictly tell it to use select from dplyr
    mutate(series    = "Credit Spread",
           full_name = "ICE BofA Euro High Yield Index Option-Adjusted Spread"),
  industrial %>% 
    dplyr::select(date, value) %>% 
    mutate(series    = "Industrial Production",
           full_name = "Germany: Industrial Production Volume (Excl. Construction)"),
  cpi %>% 
    dplyr::select(date, value) %>% 
    mutate(series    = "Consumer Price Index",
           full_name = "Germany: Harmonized Consumer Price Index (HICP, All Items)")
)

# Set color palette 
series_colors <- c(
  "Credit Spread"        = "#1f77b4", 
  "Industrial Production" = "#ff7f0e", 
  "Consumer Price Index"  = "#2ca02c" 
)
# Create a custom template for plots ----
theme_academic_individual <- function(base_size = 12) {
  theme_bw(base_size = base_size) + 
    theme(
      plot.title      = element_text(face = "bold", size = rel(1.2), hjust = 0.5),
      plot.subtitle   = element_text(size = rel(0.9), hjust = 0.5, margin = margin(b = 10)),
      axis.title.x    = element_text(size = rel(1.0), margin = margin(t = 10)),
      axis.title.y    = element_text(size = rel(1.0), margin = margin(r = 10)),
      axis.text       = element_text(size = rel(0.9)),
      panel.grid.minor= element_blank(),
      panel.grid.major= element_line(color = "grey85", linewidth = 0.4),
      plot.caption    = element_text(size = rel(0.8), hjust = 0, margin = margin(t = 10)),
      plot.margin     = margin(10, 15, 10, 10) # t, r, b, l
    )
}


# Function to create nice axisbreaks for every plot automatically ---
create_nice_breaks <- function(min_val, max_val, n = 5) {
  pretty(c(min_val, max_val), n)
}

# Create and save individual plots ----

# Plot 1: Credit Spread
data_credit <- data_raw %>% filter(series == "Credit Spread")
plot_credit_spread <- ggplot(data_credit, aes(x = date, y = value)) +
  geom_line(color = series_colors["Credit Spread"], linewidth = 0.8) +
  scale_x_date(
    date_breaks = "2 years",
    date_labels = "%Y",
    limits      = c(min(data_raw$date), max(data_raw$date)), # Consistent x-axis range
    expand      = c(0.01, 0.01)
  ) +
  scale_y_continuous(
    name   = "Credit Spread (Percentage Points)",
    breaks = create_nice_breaks(min(data_credit$value), max(data_credit$value), n = 6) # More breaks
  ) +
  labs(
    title   = "ICE BofA Euro High Yield Index Option-Adjusted Spread (2000-2019)", # More focused title
    x       = "Date",
    caption = "Source: ICE Data Indices via FRED (BAMLHE00EHYIOAS)"
  ) +
  theme_academic_individual()

print(plot_credit_spread)

# Save Credit Spread Plot 
ggsave("credit_spread_plot.pdf", plot_credit_spread, width = 7, height = 5)


# Plot 2: Industrial Production
data_industrial <- data_raw %>% filter(series == "Industrial Production")
plot_industrial_production <- ggplot(data_industrial, aes(x = date, y = value)) +
  geom_line(color = series_colors["Industrial Production"], linewidth = 0.8) +
  scale_x_date(
    date_breaks = "2 years",
    date_labels = "%Y",
    limits      = c(min(data_raw$date), max(data_raw$date)),
    expand      = c(0.01, 0.01)
  ) +
  scale_y_continuous(
    name   = "Index 2015=100",
    breaks = create_nice_breaks(min(data_industrial$value), max(data_industrial$value), n = 6)
  ) +
  labs(
    title   = "Germany: Industrial Production Volume (excl. construction, 2000-2019)",
    x       = "Date",
    caption = "Source: OECD via FRED (DEUPROINDMISMEI)"
  ) +
  theme_academic_individual()

print(plot_industrial_production)

# Save Credit Spread plot 
ggsave("industrial_production_plot.pdf", plot_industrial_production, width = 7, height = 5)


# Plot 3: Consumer Price Index
data_cpi <- data_raw %>% filter(series == "Consumer Price Index")
plot_cpi <- ggplot(data_cpi, aes(x = date, y = value)) +
  geom_line(color = series_colors["Consumer Price Index"], linewidth = 0.8) +
  scale_x_date(
    date_breaks = "2 years",
    date_labels = "%Y",
    limits      = c(min(data_raw$date), max(data_raw$date)),
    expand      = c(0.01, 0.01)
  ) +
  scale_y_continuous(
    name   = "Germany: Harmonized CPI (Index 2015=100)",
    breaks = create_nice_breaks(min(data_cpi$value), max(data_cpi$value), n = 6)
  ) +
  labs(
    title   = "Germany: Harmonized CPI (All items, 2000-2019)",
    x       = "Date",
    caption = "Source: OECD via FRED (DEUCPIALLMINMEI)"
  ) +
  theme_academic_individual()

print(plot_cpi)

# Save CPI Plot 
ggsave("cpi_plot.pdf", plot_cpi, width = 7, height = 5)

# Creating a Combined Plot 
combined_plot <- grid.arrange(plot_credit_spread, plot_industrial_production, plot_cpi, ncol = 1)
ggsave("exercise_1_combined_plot.pdf", combined_plot, width = 8, height = 12)

```

```{r exercise_1_graphcis, results='asis'}
knitr::include_graphics("exercise_1_combined_plot.pdf")
```

### Comment on these time series Plots

**Credit Spread Plot**

Before turning to the first plot, we briefly introduce the nature and construction of this time series, as it is less conventional than the other two, which most Economists should be familiar with. The ICE BofA Euro High Yield Index Option-Adjusted Spread (OAS) measures the additional yield that investors require, over the euro area risk-free rate, to hold euro-denominated corporate bonds rated below investment grade (i.e., lower than BB by Fitch or Ba1 by Moody’s). Only publicly issued bonds with an outstanding volume above €100 million from issuers domiciled in countries with investment-grade sovereign ratings are included. The spread is adjusted for embedded options and aggregated using market-capitalization weighting. In "less technical" terms, the series captures the risk premium compared to the spot Treasury curve associated with holding Eurozone "junk" bonds, reflecting both credit and liquidity risk.

The plot shows that the credit spread generally fluctuates within a 3–5 percentage point band during stable periods. Sharp spikes in the spread coincide with major episodes of financial turmoil. The elevated spread in 2001–2003, peaking around 15%, reflects heightened risk perceptions during the burst of the "dot-com-bubble" and the post-9/11 recession. The most pronounced increase occurs during the global financial crisis (2007–2009), with a peak above 20% following the collapse of the US-Bank Lehman Brothers in September 2008. The final surge in our time series between 2011 and 2013 reflects the European sovereign debt crisis.

However, it is important to note that the index only includes high-yield corporate bonds issued by firms domiciled in countries with investment-grade sovereign ratings, such as Germany. As a result, it does not fully capture the sharp rise in credit spreads for corporations based in fiscally less stable countries like Greece and Portugal, both of which lost investment-grade status in 2010. The observed increase in spreads during the European debt crisis thus primarily reflects broader market risk aversion and heightened perceptions of credit risk among issuers in core Eurozone economies—particularly those expected to act as lenders of last resort. For our analysis this is exactly what we want to focus on.

For our time series analysis, visually inspecting the series we see the series exhibits strong mean-reversion around a constant level and no visible trend, suggesting weak stationarity.

**Industrial Production Index**

The second plot shows Germany's industrial production index (excluding construction) from 2000 to 2019, expressed in real terms with 2015 as the base year. We can divide the evolution of the series into several key phases. From 2003 to mid-2008, the index displays a steady and almost linear upward trend, reflecting sustained industrial growth. This is followed by a sharp contraction of over 20% during the global financial crisis. The recovery begins in early 2009 but remains gradual and volatile. Pre-crisis output levels are only reached again by late 2015, an astounding 7 years after the GFC began. After 2017, the series begins to decline again, with little evidence of structural growth, indicating a potential stagnation of the German industrial sector in the face of increasing global uncertainty.

This time series effectively captures the cyclical and structural dynamics of Germany’s export-oriented manufacturing economy. The dramatic collapse in 2008–2009 underscores Germany's exposure to global trade disruptions during the financial crisis. The sluggish recovery and cyclical fluctuations reflect subsequent headwinds, including the euro area sovereign debt crisis (2011–2012) and the China-led global slowdown in 2015—particularly relevant given China’s role as a major importer of German industrial goods. The post-2017 downturn likely stems from declining external demand and rising global trade tensions.

Visual inspection suggests that the series is clearly non-stationary, characterized by both a deterministic trend and a shift in level post GFC. To obtain a stationary series, we take the first difference of the outcome. Additionally, we will use a logarithmic transformation as log-differences can be interpreted as month-over-month growth rates in industrial production.

**Consumer Price Index**

The third plot show the harmonized consumer price index (HICP) for Germany from 2000 to 2019, with 2015 as the base year. Over the entire sample period, the series exhibits a smooth and almost linear upward trend, increasing from approximately 80 to 105. Assuming linearity, this corresponds to an average annual growth rate of roughly 1.25 percentage points, which is consistent with the broader macroeconomic environment of low and stable inflation during this time period. Notably, the sample ends just before two major inflationary shocks: the COVID-19 pandemic and the 2022 energy crisis triggered by Russia’s invasion of Ukraine—both of which led to significant price pressures in subsequent years.

Throughout the period shown, the index displays no signs of mean reversion, and inflation appears largely unaffected by the external shocks visible in the other two series. Based on visual inspection, the series clearly exhibits a deterministic trend component. Thus, it may still be trend-stationary. To determine whether the process is stationary or not, we will conduct formal unit root tests in the next exercise, which will provide more robust evidence regarding the stationarity properties of the series. If we conclude, at least as a first step, that the series is non-stationary, we will apply log differencing, consistent with our approach to the IPI series. This transformation may yield a stationary process and additionally offers a smooth interpretation as month-over-month inflation rates.

## Exercise 1.2: Conduct unit root and stationarity tests for each series

Given our previous results, we now propose to conduct unit root and stationarity tests in the following order:

1)  We log-transform CPI and IPI for two reasons. First, the underlying trends in these series appear to be multiplicative rather than linear. Taking logs allows us to linearize the relationship, which is necessary to apply linear time series models such as AR or ARMA. Second, since we will later difference the series to achieve stationarity (based on our earlier visual inspection suggesting I(1) behavior), the log-differenced series can be conveniently interpreted as month-over-month growth rates.

2)  We proceed by conducting standard unit root and stationarity tests in the following order: – First, we apply the ADF, ERS/DF_GLS, Phillips-Perron, and KPSS tests to the original (non-differenced) series to check for stationarity of the original series – If these tests suggest non-stationarity, we continue by applying same tests (altough with possibly different trend specifications) to the first-differenced series. If those are found to be stationary, this confirms that the series are integrated of order one, I(1)

```{r exercise_1/2, include=FALSE}

## Exercise 1.2 Unit Root and Stationarity tests 

# 1. Take Logs and deltas of time series ----

industrial <- industrial %>% 
  mutate(log_value = log(value))  %>% 
  mutate(dlog_value = log_value - lag(log_value)) %>%
  drop_na(dlog_value) # Drop first observation because of NA (othwerwise VARselect won't work)



cpi <- cpi %>% 
  mutate(log_value = log(value))  %>% 
  mutate(dlog_value = log_value - lag(log_value)) %>%
  drop_na(dlog_value) # Drop first observation because of NA (othwerwise VARselect won't work)

# Take FD for credit spreads --> No Log Transformation here 
credit_spread <- credit_spread %>%
  mutate(cs_d1= credit_spread$value - lag(credit_spread$value)) %>%
  drop_na(cs_d1)

# 1.2 Briefly look at plots of the Transformed Data 

plot(industrial$dlog_value) # no visible trend, fluctuates around constant mean close to 0 --> DRIFT 
plot(cpi$dlog_value) # more more volatile, no visible trend, fluctuates around constant around mean a bit > 0  --> DRIFT
plot(credit_spread$cs_d1) # looks stationary around 0, with crisis outliers 

# 2. Unit Root tests ----

# 2.1 Use the VARS function to check the optimal # of lags ---- 
## Reminder: We are using monthly data so reasonable maximum lag order for monthly data is 12 months
# Use AIC for lag selection in ADF tests (Ng & Perron 2001 Lag Length Selection and the Construction of Unit Root Tests with Good Size and Power) 
# AIC better size and power for unit root tests 

VARselect(industrial$log_value, lag.max=12) #Result: AIC: 8 --> choose 7
VARselect(cpi$log_value, lag.max=12) #AIC 12 
VARselect(industrial$dlog_value, lag.max=12) #Result: AIC: 7 --> choose 7
VARselect(cpi$dlog_value, lag.max=12) #Result: consensus 12 lags 
VARselect(credit_spread$value, lag.max=12) # Result: AIC: 7  --> choose 7 Lags 
VARselect(credit_spread$cs_d1, lag.max = 12) # AIC: 6


## 2.1. Unit Root tests without Differentiation ---- 

### URCA - for unit root tests (w/o trends in the beginning only add trend if phi3: H0(trend=0)  —> reject)
### Remember use an appropriate maximum number of lags --> 12 for monthly data 
### We selected AIC lags anyway so we can let the function do this automatically and just give max # lags (12 for monthly)

#### a) Industrial Production (log‐level) with trend
adf_ip_lvl <- ur.df(industrial$log_value,
                    type       = "trend",
                    lags       = 12,
                    selectlags = "AIC")
summary(adf_ip_lvl)

pp_ip_lvl  <- ur.pp(industrial$log_value,
                    type   = "Z-tau", # trend
                    model  = "trend",
                    use.lag = 8)
summary(pp_ip_lvl)

kpss_ip_lvl <- kpss.test(industrial$log_value, null="Trend") # H0: trend stationarity 
print(kpss_ip_lvl)


#### b) CPI (log‐level) with trend
adf_cpi_lvl <- ur.df(cpi$log_value,
                     type       = "trend",
                     lags       = 12,
                     selectlags = "AIC")
summary(adf_cpi_lvl)

pp_cpi_lvl  <- ur.pp(cpi$log_value,
                     type   = "Z-tau", #trend
                     model  = "trend",
                     use.lag = 8)
summary(pp_cpi_lvl)

kpss_cpi_lvl <- kpss.test(cpi$log_value, null="Trend") #H0: trend stationarity
print(kpss_cpi_lvl)


#### c) Credit Spread (level) with drift
adf_cs_lvl <- ur.df(credit_spread$value,
                    type       = "drift",
                    lags       = 12,
                    selectlags = "AIC")
summary(adf_cs_lvl)

pp_cs_lvl  <- ur.pp(credit_spread$value,
                    type   = "Z-alpha", #no trend 
                    model  = "constant",
                    use.lag = 7)
summary(pp_cs_lvl)

kpss_cs_lvl <- kpss.test(credit_spread$value, null="Level") #H0: level stationarity 
print(kpss_cs_lvl)


# Only for Credit Spread run a Zivot–Andrews test too: allow one break in the intercept (AO specification)
## Credit Spread seems to have a structural break in 2009/2009 financial crisis 
za_cs_lvl <- ur.za(credit_spread$value,
                   model = "intercept",  # break in level
                   lag   = 7)        

summary(za_cs_lvl)

## Result not 100% safe --> we will continue working with first differences 



## 2.2 Unit Root tests with first order Differentiation for CPI and IPI ---- 
### Couldn't conclude Stationarity for any of the time series --> will now test FD for stationarrity


### a) FD log Industrial Production

adf_ip_diff <- ur.df(industrial$dlog_value,
                     type       = "drift",
                     lags       = 12,
                     selectlags = "AIC")
summary(adf_ip_diff)

pp_ip_diff  <- ur.pp(industrial$dlog_value,
                     type   = "Z-alpha",
                     model  = "constant",
                     use.lag = 7 )
summary(pp_ip_diff)

kpss_ip_diff <- kpss.test(industrial$dlog_value,
                          null = "Level")
print(kpss_ip_diff)


#### b) FD log CPI

adf_cpi_diff <- ur.df(cpi$dlog_value,
                      type       = "drift",
                      lags       = 12,
                      selectlags = "AIC")
summary(adf_cpi_diff)


pp_cpi_diff  <- ur.pp(cpi$dlog_value,
                      type   = "Z-alpha",
                      model  = "constant",
                      use.lag = 12)
summary(pp_cpi_diff)


kpss_cpi_diff <- kpss.test(cpi$dlog_value,
                           null = "Level")
print(kpss_cpi_diff)


#### c) FD levels difference Credit Spread 

adf_cs_diff <- ur.df(credit_spread$cs_d1,
                     type       = "drift",
                     lags       = 12,
                     selectlags = "AIC")
summary(adf_cs_diff)

pp_cs_diff  <- ur.pp(credit_spread$cs_d1,
                     type   = "Z-alpha",
                     model  = "constant",
                     use.lag = 6)
summary(pp_cs_diff)

kpss_cs_diff <- kpss.test(credit_spread$cs_d1,
                          null = "Level")
print(kpss_cs_diff)

```

```{r exercise_1/2_Graphs, include=FALSE}
# 1) Create plot objects
FD_IPI_graph <- ggplot(industrial, aes(x = date, y = dlog_value)) +
  geom_line(size = 0.6) +
  labs(
    title    = "First Difference Log Industrial Production",
    x        = "Date",
    y        = "Delta Log IPI"
  ) +
  scale_y_continuous(breaks = create_nice_breaks(min(industrial$dlog_value), max(industrial$dlog_value))) +
  theme_academic_individual()

FD_CPI_Graph <- ggplot(cpi, aes(x = date, y = dlog_value)) +
  geom_line(size = 0.6) +
  labs(
    title    = "First Difference of log Consumer Price Index",
    x        = "Date",
    y        = "Delta Log CPI"
  ) +
  scale_y_continuous(breaks = create_nice_breaks(min(cpi$dlog_value), max(cpi$dlog_value))) +
  theme_academic_individual()

FD_CS_graph <- ggplot(credit_spread, aes(x = date, y = cs_d1)) +
  geom_line(size = 0.6) +
  labs(
    title    = "First Difference of Credit spread series",
    x        = "Date",
    y        = "Delta Credit Spread"
  ) +
  scale_y_continuous(breaks = create_nice_breaks(min(credit_spread$cs_d1), max(credit_spread$cs_d1))) +
  theme_academic_individual()

# 2) Save each to its own PDF
ggsave("FD_IPI_graph.pdf", FD_IPI_graph, width = 8, height = 4, device = "pdf")
ggsave("FD_CPI_Graph.pdf", FD_CPI_Graph, width = 8, height = 4, device = "pdf")
ggsave("FD_CS_graph.pdf", FD_CS_graph, width = 8, height = 4, device = "pdf")
```

```{r exercise_1/2_Tables, include = FALSE}
##— Set NA rendering ----------------------------------------------------------
options(knitr.kable.NA = "-")

##— Load libraries -------------------------------------------------------------
library(knitr)
library(kableExtra)
library(dplyr)

##— Extract functions ---------------------------------------------------------
extract_adf_results <- function(test_obj) {
  ts <- test_obj@teststat[1]
  cv <- test_obj@cval[1, ]
  list(
    test_stat  = round(ts,   3),
    crit_1pct  = round(cv[1],3),
    crit_5pct  = round(cv[2],3),
    crit_10pct = round(cv[3],3)
  )
}
extract_pp_results <- extract_adf_results

# KPSS critical values are fixed, not the truncation lag
extract_kpss_results <- function(test_obj, null = c("level","trend")) {
  null <- match.arg(null)
  crits <- if (null == "trend") {
    c(`1%` = 0.220, `5%` = 0.146, `10%` = 0.119)
  } else {
    c(`1%` = 0.739, `5%` = 0.463, `10%` = 0.347)
  }
  list(
    test_stat  = round(unname(test_obj$statistic), 3),
    crit_1pct  = crits["1%"],
    crit_5pct  = crits["5%"],
    crit_10pct = crits["10%"]
  )
}

##— Gather results -----------------------------------------------------------
lvl_res <- list(
  ip_adf   = extract_adf_results(adf_ip_lvl),
  ip_pp    = extract_pp_results(pp_ip_lvl),
  ip_kpss  = extract_kpss_results(kpss_ip_lvl,  "trend"),
  cpi_adf  = extract_adf_results(adf_cpi_lvl),
  cpi_pp   = extract_pp_results(pp_cpi_lvl),
  cpi_kpss = extract_kpss_results(kpss_cpi_lvl, "trend"),
  cs_adf   = extract_adf_results(adf_cs_lvl),
  cs_pp    = extract_pp_results(pp_cs_lvl),
  cs_kpss  = extract_kpss_results(kpss_cs_lvl,  "level")
)
diff_res <- list(
  ip_adf   = extract_adf_results(adf_ip_diff),
  ip_pp    = extract_pp_results(pp_ip_diff),
  ip_kpss  = extract_kpss_results(kpss_ip_diff,  "level"),
  cpi_adf  = extract_adf_results(adf_cpi_diff),
  cpi_pp   = extract_pp_results(pp_cpi_diff),
  cpi_kpss = extract_kpss_results(kpss_cpi_diff, "level"),
  cs_adf   = extract_adf_results(adf_cs_diff),
  cs_pp    = extract_pp_results(pp_cs_diff),
  cs_kpss  = extract_kpss_results(kpss_cs_diff,  "level")
)

##— Table 1: Level Series -----------------------------------------------------
table1_data <- data.frame(
  Series           = c("Industrial Production (log)", rep("",3),
                       "CPI (log)",                    rep("",3),
                       "Credit Spread",                rep("",3)),
  Test             = c("ADF","PP","KPSS","",
                       "ADF","PP","KPSS","",
                       "ADF","PP","KPSS",""),
  Specification    = c("Trend","Trend","Trend","",
                       "Trend","Trend","Trend","",
                       "Drift","Drift","Level",""),
  `Test Statistic` = c(
    lvl_res$ip_adf$test_stat,  lvl_res$ip_pp$test_stat,  lvl_res$ip_kpss$test_stat, "",
    lvl_res$cpi_adf$test_stat, lvl_res$cpi_pp$test_stat, lvl_res$cpi_kpss$test_stat, "",
    lvl_res$cs_adf$test_stat,  lvl_res$cs_pp$test_stat,  lvl_res$cs_kpss$test_stat,  ""
  ),
  `1% Crit. Val.`  = c(
    lvl_res$ip_adf$crit_1pct,  lvl_res$ip_pp$crit_1pct,  lvl_res$ip_kpss$crit_1pct, "",
    lvl_res$cpi_adf$crit_1pct, lvl_res$cpi_pp$crit_1pct, lvl_res$cpi_kpss$crit_1pct, "",
    lvl_res$cs_adf$crit_1pct,  lvl_res$cs_pp$crit_1pct,  lvl_res$cs_kpss$crit_1pct,  ""
  ),
  `5% Crit. Val.`  = c(
    lvl_res$ip_adf$crit_5pct,  lvl_res$ip_pp$crit_5pct,  lvl_res$ip_kpss$crit_5pct, "",
    lvl_res$cpi_adf$crit_5pct, lvl_res$cpi_pp$crit_5pct, lvl_res$cpi_kpss$crit_5pct, "",
    lvl_res$cs_adf$crit_5pct,  lvl_res$cs_pp$crit_5pct,  lvl_res$cs_kpss$crit_5pct,  ""
  ),
  `10% Crit. Val.` = c(
    lvl_res$ip_adf$crit_10pct, lvl_res$ip_pp$crit_10pct, lvl_res$ip_kpss$crit_10pct, "",
    lvl_res$cpi_adf$crit_10pct,lvl_res$cpi_pp$crit_10pct,lvl_res$cpi_kpss$crit_10pct,"",
    lvl_res$cs_adf$crit_10pct, lvl_res$cs_pp$crit_10pct, lvl_res$cs_kpss$crit_10pct,""
  ),
  stringsAsFactors = FALSE
)

table1_latex <- table1_data %>%
  kable(
    format   = "latex",
    col.names = names(table1_data),
    caption   = "Unit Root and Stationarity Tests—Level Series",
    booktabs  = TRUE,
    align     = c("l","l","l",rep("c",4)),
    escape    = FALSE
  ) %>%
  kable_styling(latex_options = c("hold_position","scale_down")) %>%
  pack_rows("Industrial Production (log)", 1, 3) %>%
  pack_rows("CPI (log)", 5, 7) %>%
  pack_rows("Credit Spread", 9, 11) %>%
  footnote(
    general = c("ADF & PP: H₀ = unit root present",
                "KPSS:   H₀ = series stationary"),
    general_title = "Notes:",
    escape = FALSE
  )

##— Table 2: First Differences -----------------------------------------------
table2_data <- data.frame(
  Series           = c("Δ Industrial Production (log)", rep("",3),
                       "Δ CPI (log)",                   rep("",3),
                       "Δ Credit Spread",               rep("",3)),
  Test             = c("ADF","PP","KPSS","",
                       "ADF","PP","KPSS","",
                       "ADF","PP","KPSS",""),
  Specification    = c("Drift","Drift","Level","",
                       "Drift","Drift","Level","",
                       "Drift","Drift","Level",""),
  `Test Statistic` = c(
    diff_res$ip_adf$test_stat,  diff_res$ip_pp$test_stat,  diff_res$ip_kpss$test_stat, "",
    diff_res$cpi_adf$test_stat, diff_res$cpi_pp$test_stat, diff_res$cpi_kpss$test_stat, "",
    diff_res$cs_adf$test_stat,  diff_res$cs_pp$test_stat,  diff_res$cs_kpss$test_stat, ""
  ),
  `1% Crit. Val.`  = c(
    diff_res$ip_adf$crit_1pct,  diff_res$ip_pp$crit_1pct,  diff_res$ip_kpss$crit_1pct, "",
    diff_res$cpi_adf$crit_1pct, diff_res$cpi_pp$crit_1pct, diff_res$cpi_kpss$crit_1pct, "",
    diff_res$cs_adf$crit_1pct,  diff_res$cs_pp$crit_1pct,  diff_res$cs_kpss$crit_1pct, ""
  ),
  `5% Crit. Val.`  = c(
    diff_res$ip_adf$crit_5pct,  diff_res$ip_pp$crit_5pct,  diff_res$ip_kpss$crit_5pct, "",
    diff_res$cpi_adf$crit_5pct, diff_res$cpi_pp$crit_5pct, diff_res$cpi_kpss$crit_5pct, "",
    diff_res$cs_adf$crit_5pct,  diff_res$cs_pp$crit_5pct,  diff_res$cs_kpss$crit_5pct, ""
  ),
  `10% Crit. Val.` = c(
    diff_res$ip_adf$crit_10pct, diff_res$ip_pp$crit_10pct, diff_res$ip_kpss$crit_10pct, "",
    diff_res$cpi_adf$crit_10pct,diff_res$cpi_pp$crit_10pct,diff_res$cpi_kpss$crit_10pct,"",
    diff_res$cs_adf$crit_10pct, diff_res$cs_pp$crit_10pct, diff_res$cs_kpss$crit_10pct,""
  ),
  stringsAsFactors = FALSE
)

table2_latex <- table2_data %>%
  kable(
    format   = "latex",
    col.names = names(table2_data),
    caption   = "Unit Root and Stationarity Tests—First Differences",
    booktabs  = TRUE,
    align     = c("l","l","l",rep("c",4)),
    escape    = FALSE
  ) %>%
  kable_styling(latex_options = c("hold_position","scale_down")) %>%
  pack_rows("$\\Delta$ Industrial Production (log)", 1, 3) %>%
  pack_rows("$\\Delta$ CPI (log)", 5, 7) %>%
  pack_rows("$\\Delta$ Credit Spread", 9, 11) %>%
  footnote(
    general = c("ADF & PP: H₀ = unit root present",
                "KPSS:   H₀ = series stationary",
                "$\\Delta$ denotes first difference"),
    general_title = "Notes:",
    escape = FALSE
  )
```

### Level Series without integration:

```{r latextab1, results='asis'}
cat(table1_latex)
```

**Log Industrial Production** We obtained mixed results regarding the stationarity of the log industrial production series. Both the ADF and PP tests failed to reject a unit root at standard confidence levels, indicatin non-stationarity. However, the KPSS test indicated stationarity at the 1% and 5% levels, though it was borderline at 10%. Given this conflicting evidence and the general tendency to conclude non-stationarity in such cases, we lean towards the safer option and conclude that the series is non-stationary, requiring first-order integration.

**Log CPI** Both the ADF (–1.537) and PP (–1.564) test statistics are far above the critical values, confirming failure to reject the unit root. The KPSS test statistic (0.83) strongly exceeds all critical values, clearly rejecting trend stationarity. Together, the tests provide robust evidence that CPI (log) is non-stationary in levels, which aligns with expectations for price indices.

**Credit Spread** The ADF test statistic (–2.606) does not exceed the 5% critical value (–2.88), so we fail to reject the unit root. The KPSS test (0.807 \> all critical values) also rejects stationarity. However, the PP test shows an extremely large negative statistic (–13.002) with a near-zero p-value, strongly rejecting the null of a unit root. This conflicting evidence suggests caution, but overall, ADF and KPSS both support non-stationarity.

### I(1) Series:

```{=tex}
\begin{figure}[H]
  \centering
  \begin{subfigure}[t]{0.32\textwidth}
    \includegraphics[width=\textwidth]{FD_IPI_graph.pdf}
    \caption{Δ log IPI}
  \end{subfigure}
  \hfill
  \begin{subfigure}[t]{0.32\textwidth}
    \includegraphics[width=\textwidth]{FD_CPI_Graph.pdf}
    \caption{Δ log CPI}
  \end{subfigure}
  \hfill
  \begin{subfigure}[t]{0.32\textwidth}
    \includegraphics[width=\textwidth]{FD_CS_graph.pdf}
    \caption{Δ Credit Spread}
  \end{subfigure}
  \caption{First Differences of the Three Stationary Series}
  \label{fig:first_differences}
\end{figure}
```

First before we do the unit root tests we again plot the time series of the integrated processes for inspection and conclude the following about the appropriate setup for unit root tests: 

- **Industrial Production (Δlog IPI):** The series fluctuates around a non-zero constant mean without a trend, justifying the use of drift specifications for ADF/PP and a level null in KPSS.

- **CPI (Δlog CPI):** The differenced price index series also shows no trend, only short-term fluctuations around a stable mean. This supports the same test setup.

- **Credit Spread (Δ):** Although more volatile, especially around 2009, the series remains mean-reverting without trend, making the constant-only specification reasonable.


```{r latextab2, results='asis'}
cat(table2_latex)
```

After doing the tests, we conclude the following: 
- $\Delta$ **log Industrial Production:** All three tests now clearly point toward stationarity. ADF and PP strongly reject the unit root, while the KPSS test fails to reject level stationarity. This confirms that first differencing was sufficient to achieve stationarity for the industrial production series.

-  $\Delta$ **log CPI:** The test results are consistent and conclusive. Both the ADF and PP tests strongly reject the null of a unit root, and the KPSS test does not reject level stationarity. We therefore conclude that the first-differenced log CPI series is stationary.

- $\Delta$ **Credit Spread:** As with the other two series, all tests align. ADF and PP reject the presence of a unit root by a wide margin, and KPSS indicates no violation of level stationarity. This supports the conclusion that the differenced credit spread series is stationary.



## Exercise 1.3: Identify and estimate candidate AR(p) and ARMA(p,q) models using the ACF and PACF. Which model would you choose according to information criteria? Comment the results

```{r exercise_1/3, include=FALSE}

# Exercise 1.3 Identify and estimate candidate AR(p) and ARMA(p,q) models using ACF and PACF 
## Since we already saw that the we need to take First Differences for stationarity use the I(1) of the series for ACF and PACF Plots

## 1. Create ACF and PACF Plots for our differentiated series (visual inspection) ---- 

### A. Industrial (Dif log IPI)
p_ipi_acf  <- ggAcf(industrial$dlog_value, lag.max = 20) + labs(title="ACF: Δ log(Industrial Production Index)")
p_ipi_pacf <- ggPacf(industrial$dlog_value, lag.max = 20) + labs(title="PACF: Δ log(Industrial Production Index)")
(ipi_acf <- p_ipi_acf / p_ipi_pacf) + plot_layout(guides="collect")
ggsave("ipi_acf_grid.pdf", ipi_acf, width = 8, height = 4)

#### B. CPI (Dif log CPI)
p_cpi_acf  <- ggAcf(cpi$dlog_value, lag.max = 20) + labs(title="ACF: Δ log(CPI)")
p_cpi_pacf <- ggPacf(cpi$dlog_value, lag.max = 20) + labs(title="PACF: Δ log(CPI)")
(cpi_acf <- p_cpi_acf / p_cpi_pacf) + plot_layout(guides="collect")
ggsave("cpi_acf_grid.pdf", cpi_acf, width = 8, height = 4)

### C. Credit Spread (Dif CS)
p_cs_acf  <- ggAcf(credit_spread$cs_d1, lag.max = 20) + labs(title="ACF: Δ Credit Spread")
p_cs_pacf <- ggPacf(credit_spread$cs_d1, lag.max = 20) + labs(title="PACF: Δ Credit Spread")
(cs_acf <- p_cs_acf / p_cs_pacf) + plot_layout(guides="collect")
ggsave("cs_acf_grid.pdf",  cs_acf,  width = 8, height = 4)


#### Results
# IPI: AR(3)
# CPI: Looks almost like White Noise > at most MA(1) if Ljung Box test fails
# CS: AR(1) or AR(6) because of the significant downward spike of PACF at lag 6 

## 1) Gather the three stationary series in a named list --------------
ts_list <- list(
  industrial     = industrial$dlog_value,
  core_infl      = cpi$dlog_value,
  credit_spread  = credit_spread$cs_d1
)

## 2) Helper: exhaustive (p,q) grid, return top-N by AIC & BIC ---------
get_top_models <- function(y, max_p = 7, max_q = 7, n = 5) {
  grid <- expand.grid(p = 0:max_p, q = 0:max_q)
  grid$AIC <- grid$BIC <- NA_real_
  
  for (i in seq_len(nrow(grid))) {
    # wrap in try() so a non-invertible candidate doesn’t kill the loop
    fit_try <- try(
      Arima(y,
            order            = c(grid$p[i], 0, grid$q[i]),
            include.constant = TRUE,          # OK even after differencing
            method           = "ML"),
      silent = TRUE)
    
    if (!inherits(fit_try, "try-error")) {
      grid$AIC[i] <- fit_try$aic
      grid$BIC[i] <- fit_try$bic
    }
  }
  
  list(
    topBIC = head(grid[order(grid$BIC), ], n),
    topAIC = head(grid[order(grid$AIC), ], n)
  )
}

## 3) Apply to each series; store top-5 tables + BIC-winner fit ---------
all_models <- lapply(ts_list, function(y) {
  tops <- get_top_models(y)
  best <- tops$topBIC[1, ]
  
  best_fit <- Arima(y,
                    order            = c(best$p, 0, best$q),
                    include.constant = TRUE,
                    method           = "ML")
  
  list(
    topBIC  = tops$topBIC,
    topAIC  = tops$topAIC,
    fit_obj = best_fit
  )
})

## 4) Console output – top 5 by BIC and AIC -----------------------------
for (nm in names(all_models)) {
  cat("\n=== Series:", nm, "===\n")
  cat("Top 5 by BIC:\n")
  print(all_models[[nm]]$topBIC, row.names = FALSE)
  cat("\nTop 5 by AIC:\n")
  print(all_models[[nm]]$topAIC, row.names = FALSE)
}

## D. Extra Approach: Use algorithmic search for ARIMA Process (Hyndman-Khandakar algorithm)
### run auto.arima on each
auto_models <- lapply(ts_list, function(y) {
  auto_fit <- auto.arima(y, seasonal = FALSE, ic = "bic",
                         stepwise = TRUE # Turned on for speed as this is a mere Bonus application
                         )
  
### capture summary info
  info <- list(
    model = auto_fit,
    p     = auto_fit$arma[1],
    q     = auto_fit$arma[2],
    AIC   = auto_fit$aic,
    BIC   = auto_fit$bic
  )
  info
})

### print out results
for (nm in names(auto_models)) {
  m <- auto_models[[nm]]
  cat("\n---", toupper(nm), "---\n")
  cat(sprintf("auto.arima chose ARMA(%d,%d)\n", m$p, m$q))
  cat(sprintf("   AIC = %.3f,   BIC = %.3f\n", m$AIC, m$BIC))
  print(summary(m$model))
}

```

```{r exercise 1/3_tables, include=FALSE}
# Create one table per model/criterion
model_tables <- list()

for (nm in names(all_models)) {
  model_tables[[paste0(nm, "_bic")]] <- kable(
    all_models[[nm]]$topBIC, format = "latex", booktabs = TRUE,
    caption = paste("Top 5 ARMA Models by BIC for", nm)
  ) %>%
    kable_styling(latex_options = c("striped", "hold_position"))
  
  model_tables[[paste0(nm, "_aic")]] <- kable(
    all_models[[nm]]$topAIC, format = "latex", booktabs = TRUE,
    caption = paste("Top 5 ARMA Models by AIC for", nm)
  ) %>%
    kable_styling(latex_options = c("striped", "hold_position"))
}

```

### Industrial Production Index:

```{r, results='asis'}
knitr::include_graphics("ipi_acf_grid.pdf")
model_tables$industrial_bic
model_tables$industrial_aic
```

**Comment:** Inspecting the PACF plot, the pattern appears somewhat irregular. We observe a significant spike at lag 1, a non-significant lag 2, followed by another significant spike at lag 3. This suggests an autoregressive process of order between 1 and 3. As a conservative choice, we initially lean toward an AR(3) specification. This is further supported by the ranking of optimal candidates by the Bayesian Information Criterion (BIC), where the AR(3) model appears as the fourth-best candidate, performing only marginally worse than the top models.

Based on the information criteria, the BIC selects an MA(3) process as the optimal model, while the AIC favors a much more complex ARMA(5,7) specification. *(Reminder: since we are modeling the I(1) series, this corresponds to an ARIMA(5,1,7) on the original series.)* Once again, this illustrates AIC's tendency to prefer more heavily parameterized models that were not clearly supported by the ACF or PACF plots. We therefore select the MA(3) model as our preferred specification—it performs nearly as well under AIC and is more parsimonious. The MA(3) Model was also chosen by the Hyndman-Khandakar-Algorithm when optimizing with respect to the BIC.

Residual diagnostics (see final table in Exercise 1.3) confirm that the MA(3) model is well-specified. The Ljung–Box test fails to reject the null hypothesis of no autocorrelation. While the Jarque–Bera test rejects normality, this is common in empirical macroeconomic applications and not a major concern, especially since we are interested in forecasting and not inference.

### Consumer Price Index:

```{r}
knitr::include_graphics("cpi_acf_grid.pdf")
model_tables$core_infl_bic
model_tables$core_infl_aic
```

**Comment:** Looking at the MoM inflation rate (log-differenced CPI), the ACF and PACF plots show no significant autocorrelation at any lag, as all values remain well within the confidence bands. Based on visual inspection alone, this pattern is most consistent with a simple white noise process.

This impression is confirmed by the BIC, which selects an ARMA(0,0) model, i.e. pure white noise. The AIC, on the other hand, again favors a more complex model *(in this case, an ARMA(2,2) process)*. However, even under AIC, the improvement in fit relative to ARMA(0,0) is marginal and does not justify the added complexity, especially given the lack of support from the correlogram.

Turning to residual diagnostics, we fail to reject both null hypotheses of the Ljung–Box test (no autocorrelation) and the Jarque–Bera test (normality) for the white noise model. These results provide further evidence for our initial conclusion that the CPI time series—after differencing—can reasonably be modeled as a white noise process.

### Credit Spread Index:

```{r}
knitr::include_graphics("cs_acf_grid.pdf")
model_tables$credit_spread_bic
model_tables$credit_spread_aic
```

**Comment:**
Inspecting the ACF and PACF plots for the credit spread change (i.e. first difference) series again reveals a somewhat non-standard pattern. The ACF shows a large significant spike at lag 1, followed by additional significant values at lags 2 and 4, as well as a highly negative spike at lag 6. The PACF similarly exhibits a strong positive spike at lag 1 and a large negative spike at lag 6. While not a textbook case, this pattern is most plausibly associated with an AR(1) or possibly an AR(6) process.

Turning to the information criteria, the BIC selects an ARMA(1,0) process, i.e. an AR(1), as the preferred specification. The next-best BIC candidate is an MA(1), but the visual evidence does not support a pure MA process. The AIC, as before, chooses a more complex model—namely, an ARMA(1,6)—which comes with a considerable reduction in AIC relative to the AR(1) model. Nevertheless, for reasons of parsimony and interpretability, we adopt **AR(1)** as our baseline model.

Finally, examining the residual diagnostics, we find that the AR(1) model passes the Ljung–Box test (i.e., we fail to reject the null of no autocorrelation), while the Jarque–Bera test again rejects normality, typical for Macroeconometrics. Based on these results, we conclude that the AR(1) specification sufficiently captures the serial dependence in the credit spread series.

### Residual Diagnostics:

```{r diagnostic_tables, results='asis'}
#–– Optional: map internal names to pretty labels ––
pretty_names <- c(
  industrial = "Industrial Production Index",
  core_infl = "Core Inflation",
  credit_spread = "Credit Spread"
)

#–– 1) Extract top 1 by BIC and top 1 by AIC for each series ––
diag_list <- lapply(names(all_models), function(series) {
  # grab the top candidates
  bic_row <- all_models[[series]]$topBIC[1, ]
  aic_row <- all_models[[series]]$topAIC[1, ]
  rows   <- rbind(bic_row, aic_row)
  
  # loop over BIC/AIC rows
  do.call(rbind, lapply(seq_len(nrow(rows)), function(i) {
    p <- rows$p[i]
    q <- rows$q[i]
    # fit the model
    fit <- Arima(
      ts_list[[series]],
      order            = c(p, 0, q),
      include.constant = TRUE,
      method           = "ML"
    )
    res <- residuals(fit)
    # diagnostics
    lb <- Box.test(res, lag = 20, type = "Ljung-Box")
    jb <- jarque.bera.test(res)
    data.frame(
      Series    = pretty_names[series],
      Criterion = c("BIC", "AIC")[i],
      Model     = sprintf("ARMA(%d,%d)", p, q),
      `LB Stat` = round(lb$statistic, 2),
      `LB p-val`= sprintf("%.3f", lb$p.value),
      `JB Stat` = round(jb$statistic, 2),
      `JB p-val`= sprintf("%.3f", jb$p.value),
      check.names = FALSE,
      stringsAsFactors = FALSE
    )
  }))
})

#–– 2) Combine and print LaTeX table ––
diag_tbl <- do.call(rbind, diag_list)
print(
  xtable(
    diag_tbl,
    caption = "Residual diagnostics for top ARMA models by BIC and AIC",
    label   = "tab:resid_top_bic_aic"
  ),
  include.rownames      = FALSE,
  booktabs              = TRUE,
  caption.placement     = "top",
  sanitize.text.function = identity
)
```

## Exercise 1.4: For one of the series, plot the in-sample and out-of-sample forecasts from your best model. Comment the results

We now plot the in-sample and out-of-sample forecasts for the MOM growth of the Industrial Production series. While the MA(3) initially performed best in terms of BIC, MA models are generally less suited for forecasting since they rely on unobservable future shocks. By contrast, AR processes only depend on past information, making them operationally more robust. Given that the AR(3) process performs nearly as well on the BIC and passes key residual diagnostics (Ljung–Box), we proceed with it for this exercise.


```{r exercise_1/4, include = FALSE}

# Step 0: Check if AR(3) process is also suited for forecasting here ----
fit_ar3 <- Arima(ts_list$industrial, order = c(3, 0, 0), include.constant = TRUE)

#–– Residual diagnostics ––
lb <- Box.test(residuals(fit_ar3), lag = 20, type = "Ljung-Box")
jb <- jarque.bera.test(residuals(fit_ar3))

cat("Ljung–Box p-value:", round(lb$p.value, 3), "\n")
cat("Jarque–Bera p-value:", round(jb$p.value, 3), "\n")





# Step 1: Estimate the Forecasts ----

ipi_ts <- ts(ts_list$industrial, start = c(2000, 1), frequency = 12) #full sample time 
ipi_s1 <- window(ipi_ts, end = c(2018, 12)) # training sample

# Estimate AR 3 Model using arima function
ar3_s1 <- Arima(ipi_s1, order = c(3, 0, 0))

#–– Save In-sample fit plot to PDF ––
pdf("AR3_InSample_Fit.pdf", width = 8, height = 5)
plot(cbind(ipi_s1, ar3_s1$fitted), plot.type = "s", col = c("black", "red"), lty = 1,
     main = "AR(3) In-Sample Fit – MOM change Industrial Production in %",
     ylab = "Δlog IPI", xlab = "Time")
legend("topright", legend = c("Actual", "In-sample fit (AR(3))"),
       col = c("black", "red"), lty = 1, bty = "n")
dev.off()

#–– Save Out-of-sample forecast plot to PDF ––
ar3_s1_fc <- forecast(object = ipi_s1, model = ar3_s1, h = 12)
pdf("AR3_OutSample_Forecast.pdf", width = 8, height = 5)
plot(ar3_s1_fc, main = "AR(3) Out-of-Sample Forecast – MOM change in Industrial Production in %",
     ylab = "Δlog IPI", xlab = "Time")
dev.off()

```

\begin{figure}[H]
  \centering
  \begin{minipage}[t]{0.48\textwidth}
    \centering
    \includegraphics[width=\linewidth]{AR3_InSample_Fit.pdf}
    \caption*{In-Sample Fit – AR(3)}
  \end{minipage}%
  \hfill
  \begin{minipage}[t]{0.48\textwidth}
    \centering
    \includegraphics[width=\linewidth]{AR3_OutSample_Forecast.pdf}
    \caption*{Out-of-Sample Forecast – AR(3)}
  \end{minipage}
\end{figure}

## Comment on the Plots: 

**In-Sample Fit**  
The first plot compares the AR(3) model’s in-sample predictions (red) with the actual data (black). Overall, the model captures the general direction and persistence in $\Delta \log$ IPI reasonably well. However, the fit is clearly smoother than the actual series, particularly drastic shocks, around the 2009 GFC, are not fully reflected. This is expected: linear autoregressive models tend to average over past fluctuations and are typically not well-suited to capture crisis dynamics. Still, the model offers a decent approximation of the underlying process.

**Out-of-Sample Forecast**  
The second plot presents the out-of-sample forecast with confidence intervals. The forecast shows some minor variation early on but quickly reverts to a constant mean, as expected for a stationary AR(p) process. Since we're using an AR(3) model for a 12-month horizon, real input data beyond the first few periods becomes unavailable, limiting dynamic response. The wide confidence bands indicate high uncertainty, which is not surprising given the volatility of the series. In short, the model suggests short-term stability but lacks precision for medium- or long-run projections.

**Conclusion**  
The AR(3) model provides a reasonable short-term baseline, capturing autocorrelation but smoothing over extreme movements. For more accurate or structural insights, models with additional indicators (e.g., VAR) would be more appropriate. To better understand crisis episodes, nonlinear time series methods should be considered, as linear models struggle to capture such dynamics.

# Exercise 2 - : Multivariate analysis

```{r prepare_ex2, include = FALSE}

# Clean up environment again after exercise 1  
rm(list=ls())

knitr::opts_chunk$set(echo=FALSE, warning=FALSE, message=FALSE)

# 1. Import the Data ---- 

# Setup
fredr_set_key("8af1b2f98eef41dfe4b5ff6ffce1bbb0")
start_date <- as.Date("2000-01-01")
end_date   <- as.Date("2019-12-31")

# Import Values 

industrial    <- fredr("DEUPROINDMISMEI",
                       observation_start = start_date,
                       observation_end   = end_date,
                       frequency         = "m")
credit_spread <- fredr("BAMLHE00EHYIOAS",
                       observation_start = start_date,
                       observation_end   = end_date,
                       frequency         = "m",
                       aggregation_method= "avg")
cpi           <- fredr("DEUCPALTT01IXOBSAM",
                       observation_start = start_date,
                       observation_end   = end_date,
                       frequency         = "m")

# Extract value columns as numeric vectors
ip_vec  <- industrial$value
cs_vec  <- credit_spread$value
cpi_vec <- cpi$value

# Take First  Differences (Integration of order 1)
ip_diff  <- diff(log(ip_vec)) # log for interpretability 
cpi_diff <- diff(log(cpi_vec)) # log for interpretability 
cs_diff <- diff(cs_vec)


# Combine all differenced series into a single multivariate time series object
data_mat <- ts(
  cbind(ip = ip_diff,
        cpi = cpi_diff,
        cs  = cs_diff),
  start     = c(2000, 2), # start from 2nd observation (due to differencing)
  frequency = 12 # monthly
)

```

## Exercise 2.1: Select the optimal lag length for your multivariate model

```{r exercise2/1, include=FALSE}
sel <- VARselect(data_mat, lag.max = 8, type = "const")
sel$selection
```

**Comment:**  
The lag selection criteria point to different optimal values: both AIC *(Akaike Information Criterion)* and FPE *(Final Prediction Error)* suggest a lag length of 6, while HQ *(Hannan–Quinn)* selects 3 and SC *(Schwarz Criterion)* selects 1. Following standard practice, we prioritize the more parsimonious criteria, HQ and SC, which recommend lag orders of 3 and 1, respectively.

Among these, we choose lag 3, as selected by the HQ criterion. While this includes fewer lags than the AIC-optimal specification, it still ensures that residuals are approximately serially uncorrelated (as confirmed in Question 2), which is essential for valid inference and for interpreting impulse response functions. In addition, a more parsimonious model reduces the risk of overfitting, which is particularly important in finite samples.


## Exercise 2.2: Estimate the model and verify that the residuals satisfy standard properties

```{r exercise2/2, results='asis'}
p_opt   <- sel$selection["AIC(n)"]
var_mod <- VAR(data_mat, p = p_opt, type = "const")
summary(var_mod)


cat("\n--- Portmanteau (no serial correlation) ---\n")
print(serial.test(var_mod, lags.pt = 12, type = "PT.asymptotic"))

cat("\n--- ARCH (no ARCH effects) ---\n")
print(arch.test(var_mod, lags.multi = 5))

cat("\n--- Normality ---\n")
print(normality.test(var_mod))
```


**Comment:** 
There is no evidence of serial correlation at lag = 6. This is cinfimed by both The errors are not homoskedastic and they are also not normally distributed, which contradicts white noise. The errors are therefore not well-behaved and some robust techniques need to be used in order to work with this VAR. This is beacuse hypothesis testing is not valid if the errors are not well-behaved. The p-value for the Portmanteau test is 0.1929 which shows that we fail to reject the Null hypothesis that there is no serial autocorrelation. However, the p-values for the JB-test and the ARCH test on normality and heteroskedastcity are well-below 0.05 which means that we reject the null hypotheses. 


## Exercise 2.3: Plot the in-sample and out-of-sample forecasts for one of the series

```{r exercise2/3, echo=TRUE, fig.height=5, fig.width=8}

# 1) In-sample fit vs actual
ts_hist   <- ts(data_mat[,"cpi"],
                start     = start(data_mat),
                frequency = frequency(data_mat))
ts_fitted <- ts(fitted(var_mod)[,"cpi"],
                start     = start(data_mat),
                frequency = frequency(data_mat))

# 2) Out-of-sample forecast
fcast   <- predict(var_mod, n.ahead = 12, ci = 0.95)
cpi_mat <- fcast$fcst[["cpi"]]
ts_fc    <- ts(cpi_mat[,"fcst"],
               start     = end(data_mat) + c(0,1),
               frequency = frequency(data_mat))
ts_lo    <- ts(cpi_mat[,"lower"],
               start     = start(ts_fc),
               frequency = frequency(data_mat))
ts_hi    <- ts(cpi_mat[,"upper"],
               start     = start(ts_fc),
               frequency = frequency(data_mat))


par(mfrow = c(1,2), mar = c(4,4,2,1))

# Panel 1
plot(ts_hist,
     ylab = expression(Δ~log~CPI),
     xlab = "Years",
     main = "Actual vs. Fitted CPI",
     col  = "black", lty = 1)
lines(ts_fitted, col = "red", lty = 2)
legend("topleft",
       legend = c("Actual","Fitted"),
       col    = c("black","red"),
       lty    = c(1,2),
       bty    = "n")

# Panel 2
plot(ts_hist,
     xlim = c(time(ts_hist)[1], time(ts_hi)[length(ts_hi)]),
     ylim = range(c(ts_hist, ts_lo, ts_hi)),
     ylab = expression(Δ~log~CPI),
     xlab = "Years",
     main = "CPI 1-Yr Ahead Forecast",
     col  = "black", lty = 1)
abline(v = time(ts_fc)[1], lty = 3, col = "grey")
lines(ts_fc, col = "blue", lty = 1)
lines(ts_lo, col = "red",  lty = 2)
lines(ts_hi, col = "red",  lty = 2)
legend("topright",
       legend = c("History","Forecast","95% CI"),
       col    = c("black","blue","red"),
       lty    = c(1,1,2),
       bty    = "n")


par(mfrow = c(1,1))

``` 
Panel 1: Actual vs. Fitted CPI

In the first graph we see that the actual and the fitted inflation rate (log difference of CPI) seem to be pretty similar expect for a few months. The early 2015 deflationary episode is not well picked up by the fitted values and so is the inflation around 2008-09 which is unsurprising considering the unexpected financial crisis. The 2015 deflationary episode could be due to the collapse of oil prices globally around that period. 

Panel 2: CPI 1-Year Ahead Forecast

The one-year forecasts show a slight deflationary trend at the start and then a subtle bout of inflation from the summer down to the end. The confidence intervals (the red dotted lines around the blue dashed line) grow over time because the more ahead in the forecast the more uncertainty we have over what could happen and therefore the more unsure our estimates are. However, we need to be careful with these confidence intervals because they are analytic and the non-Gaussian characteristics of our residuals mean that they could be biased. In fact, their validity relies on the Gaussian behaviour of the residuals. The bootstrapped intervals which are not shown here but which we will use later are robust to this issue of heteroskedasticity.  

## Exercise 2.4: Using the Cholesky decomposition, explain the reasoning behind your chosen ordering of variables

```{r exercise 2/4, echo = FALSE}

data_chol <- data_mat[, c("cs","cpi","ip")]
var_chol  <- VAR(data_chol, p = p_opt, type = "const")
summary(var_chol)

```
The order we chose is credit spread first, inflation second and industrial production last. This is because the the first thing that responds to any global financial shock is the financial market, i.e. the credit spread. Next, the effects trickle down to affect the inflation rate and from there they hit the industrial production last. The progressively lagged responses that are associated with each series is what motivated us to order the processes this way.


## Exercise 2.5: Show the orthogonalized impulse response functions for your system

```{r five, echo=FALSE, fig.show='hold', fig.height=8, fig.width=6}

data_chol <- data_mat[, c("cs","cpi","ip")]


var_chol  <- VAR(data_chol, p = p_opt, type = "const")



oirf      <- irf(var_chol,
                 impulse  = NULL,   
                 response = NULL,   
                 ortho    = TRUE,
                 boot     = TRUE,
                 ci       = 0.95,
                 runs     = 500,)





# impulses and responses
impulses <- names(oirf$irf)               # e.g. c("cs","cpi","ip")
responses <- colnames( oirf$irf[[1]] )    # same

# set up 3×3 plotting region
op <- par(mfrow = c(length(responses), length(impulses)),
          mar   = c(4, 4, 2, 1) + 0.1,
          las   = 1)

for(imp in impulses) {
  # pull out the  matrix for this impulse
  resp_mat  <- oirf$irf[[imp]]   # rows = horizons 1…n.ahead
  lower_mat <- oirf$Lower[[imp]]
  upper_mat <- oirf$Upper[[imp]]

  # how many horizons do we actually have?
  H <- nrow(resp_mat)
  # build horizon from 0 to H
  h <- 0:H

  for(resp in responses) {
    # prepend the t=0 value (own‐shock magnitude = 1)
    irf_vec <- c(1, as.numeric(resp_mat[,resp]))
    lo_vec  <- c(1, as.numeric(lower_mat[,resp]))
    hi_vec  <- c(1, as.numeric(upper_mat[,resp]))

    plot(h, irf_vec,
         type  = "l",
         lty   = 1,
         xlab  = "Horizon (months)",
         ylab  = resp,
         main  = paste0("Response of ", resp,
                        " to a ", imp, " shock"),
         ylim  = range(c(lo_vec, hi_vec)))
    lines(h, lo_vec, lty = 2)
    lines(h, hi_vec, lty = 2)
    abline(h = 0, col = "grey60")
  }
}









par(op)

```



Applying the Cholesky ordering we imposed, a shock affects credit spread which then affects inflation which then affects IP: 

Panel 1: We look at the effect of a one SD credit spread shock on each variable. A credit shock increases CS by 0.8 units at t = 1 and then decays quite quickly; at t = 2 it is already at just 0.2 of a standard deviation. After five months the model implies it slightly dips under zero and then reverts back to its mean value of zero. The effect on CPI and IP shock is virtually constant and null. We can therefore say that a one standard deviation shock of CS has no statistically significant effect on CPI and IP. The CI follow the shape of the series throughout and tightly sandwich the series making the plot trustworthy.

Panel 2: We look at the effect of a one standard-deviation shock of CPI. We see that it makes the CS increase slightly by around 0.1 and then it goes up and down slightly period by period before it dissipates towards its mean zero at the end. Its effect on inflation and industrial production are essentially zero. 

Panel 3: Here we see the effect of a one SD shock of industrial production. On the CS we can see that it zig-zags around zero going from positive to negative for about 6 periods before reverting to zero. The effect on inflation and IP is basically null. 

We can conclude that the only variable that is affected by any shock in any variable is the credit spread. This is an interesting finding. It seems like inflation and industrial production is very stable in Germany and that fluctuations are only felt on the financial market. This could be a sign of a stable economy.


NB: We used the bootstrapped confidence intervals which means that they are robust under heteroskedasticity. 


## Exercise 2.6: Modify the ordering of the variables and comment how this affects your results

```{r six, echo=FALSE, fig.show='hold', fig.height=8, fig.width=6}
# reversed ordering
data_chol_rev <- data_mat[, c("ip","cpi","cs")]
var_chol_rev  <- VAR(data_chol_rev, p = p_opt, type = "const")
oirf_rev      <- irf(var_chol_rev,
                     impulse  = NULL,
                     response = NULL,
                     ortho    = TRUE,
                     boot     = TRUE,
                     ci       = 0.95,
                     runs     = 500)

# same 3×3 layout as before
impulses <- names(oirf_rev$irf)
responses <- colnames(oirf_rev$irf[[1]])

op <- par(mfrow = c(length(responses), length(impulses)),
          mar   = c(4, 4, 2, 1) + 0.1,
          las   = 1)

for(imp in impulses) {
  resp_mat  <- oirf_rev$irf[[imp]]
  lower_mat <- oirf_rev$Lower[[imp]]
  upper_mat <- oirf_rev$Upper[[imp]]

  H <- nrow(resp_mat)
  h <- 0:H

  for(resp in responses) {
    irf_vec <- c(1, as.numeric(resp_mat[,resp]))
    lo_vec  <- c(1, as.numeric(lower_mat[,resp]))
    hi_vec  <- c(1, as.numeric(upper_mat[,resp]))

    plot(h, irf_vec,
         type  = "l",
         lty   = 1,
         xlab  = "Horizon (months)",
         ylab  = resp,
         main  = paste0("Response of ", resp,
                        " to an ", imp, " shock"),
         ylim  = range(c(lo_vec, hi_vec)))
    lines(h, lo_vec, lty = 2)
    lines(h, hi_vec, lty = 2)
    abline(h = 0, col = "grey60")
  }
}

par(op)




```


Upon reversing the ordering of the propgation of shocks, i.e. IP first, then inflation and then CS, we can see that the plots look roughly the same. This means that the results are order-invariant and that the impulse responses are robust to the Cholesky ordering. This is good news as it shows that the order in which we run the IRF's is irrelevant, our results are still the same. This makes the economic conclusions more robust. We can therefore conclude that in Germany inflation and industrial production really are unaffected to an infationary shock, an industrial production shock and a CS shock. 
